---
title: "Time Series"
author: "Brayan Duran Medina"
output: html_document
---

### Monthly beer production in Australia from 1956 to 1995

# Importing libraries
```{r, message=FALSE}
library(readxl)
library(dplyr)
library(ggplot2)
library(GGally)
library(ggcorrplot)
library(MASS)
library(lmtest)
library(forecast)
library(tseries)
library(Hmisc)
library(lubridate)
```

# Reading data
```{r}
data <- read.csv("monthly-beer-production-in-austr.csv",
                 header = TRUE, sep = ",")
head(data)
```

# Preparing data
```{r}
names(data)[1] <- "Date"
names(data)[2] <- "Value"

title <- "Monthly beer production in Australia"

data$Value <- as.numeric(data$Value)
data$Date <- as.Date(as.yearmon(data$Date, format = "%Y-%m"))

head(data)
```

# Creating time series
```{r}
time_series <- ts(data = data$Value, start =
                    as.numeric(c(format(data$Date[1], "%Y"),
                                 format(data$Date[1], "%m"))), freq = 12)
```

# Plotting data
```{r}
plot(time_series, type = "l", ylab = title, col = "red")

grid()
```

### Notes:
We have too many years in the data, so the forecast will be very inaccurate. 
So then we will only use the data from 1975 to 1995, that is the last 20 years.

# Cutting data to keep only the last 20 years
```{r}
data <- data[format(data$Date, "%Y") >= 1975, ]
```

# Creating new time series with the last 20 years
```{r}
time_series <- ts(data = data$Value, start =
                    as.numeric(c(format(data$Date[1], "%Y"),
                                 format(data$Date[1], "%m"))), freq = 12)
```

# Plotting new time series
```{r}
plot(time_series, type = "l", ylab = title, col = "red")

grid()
```

# STL decomposition
```{r, fig.width=10, fig.height=10}
plot(stl(time_series, s.window = "periodic"))
```

# Box-Cox transformation
```{r, fig.width=10, fig.height=10}
par(mfrow = c(2, 1))

plot(time_series, ylab = "Original series", xlab = "", col = "red")
grid()

lambda <- BoxCox.lambda(time_series)

plot(BoxCox(time_series, lambda),
     ylab = "Transformed series", xlab = "", col = "red")

title(main = toString(round(lambda, 3)))

grid()
```

### Notes:
Looking at the plot of the original series and the transformed one, we can see that there is not so much variance in the date, 
so we will not make the Box-Cox transformation.

# Prepare train and test data (testing with the last year)
```{r}
total_length <- length(time_series)

test_length <- round(total_length / 10)

cut_off_point <- total_length - test_length

train_set <- time_series[1:cut_off_point]
test_set <- time_series[(cut_off_point + 1):total_length]

head(train_set)
head(test_set)
```

# ARIMA

## Automatic model selection
```{r, echo=FALSE, cache=TRUE}
fit_auto <- auto.arima(time_series, biasadj = TRUE)

fit_auto
```

### Notes:
The automatic model selection gives us an ARIMA(4,0,5)(1,1,2)[12] model.

## Plot of residuals
```{r, fecho=FALSE, fig.width=10, fig.height=6}
res_auto <- residuals(fit_auto)

plot(res_auto)
```

```{r, echo=FALSE, fig.width=10, fig.height=6}
par(mfrow = c(1, 2))

qqnorm(res_auto)

qqline(res_auto, col = "red")

hist(res_auto)
```

Hypothesis   | Test         | Result         | P-value
------------ | ------------ | -------------- | ------------------------------
Normality    | Shapiro-Wilk |     rejected   | `r shapiro.test(res_auto)$p.value`
Unbiasedness | Wilcoxon     | not rejected   | `r wilcox.test(res_auto)$p.value`
Stationarity | KPSS         | not rejected   | `r kpss.test(res_auto)$p.value`

## Forecast the last year using the automatic model
```{r}
fit_short <- Arima(train_set, model = fit_auto)

fc <- forecast(fit_short, h = test_length)

accuracy(fc, test_set)
```


```{r, fig.height=5, fig.width=10}
plot(fc, ylab = title, xlab = "Time")

total_set <- c(train_set, test_set)

lines(total_set, col = "red")
```

# Manual model tuning

### Notes:

The series is nonstationary (p<`r kpss.test(time_series)$p.value`, KPSS test) and clearly seasonal; let's do seasonal differencing:

```{r, fig.height=5, fig.width=10}

time_series_diff <- diff(time_series, 12)
plot(time_series_diff, type = "l", col = "red")

grid()
```

### Notes:
Now the series is stationary (p>`r kpss.test(diff(time_series, 12))$p.value`, KPSS test) and we can try to fit an ARIMA model.

## ACF and PACF plots
```{r, fig.height=5, fig.width=10}
par(mfrow = c(1, 2))

acf(time_series_diff, lag.max = 5 * 12, main = "")

pacf(time_series_diff, lag.max = 5 * 12, main = "")
```

### Notes:

ACF:

- Since 12 is maximal significant seasonal lag, we could use Q=12/12=1
as an initial approximation. Maximal significant lag before 12 is 11, hence the starting value q=11.

PACF:

- Following the same logic as above, we select initial values P=5, p=11.

Next we'll look for the best models with auto.arima using d=1, D=1, max.p=12, max.q=12, max.P=6, max.Q=2 (where possible, we
 added 1 to every initial approximation found above just in case), and the parameters of the automatic model as starting points
  of the search (start.p=11, start.q=11, start.P=5, start.Q=1).

```{r, cache=TRUE}
fit <- auto.arima(time_series, d = 1, D = 1, max.p = 12,
                  max.q = 12, max.P = 6, max.Q = 2,
                  start.p = 11, start.q = 11, start.P = 5, start.Q = 1,
                  biasadj = TRUE)

fit
```

The lowest AICc has ARIMA(1,1,2)(5,1,1)[12]. Does it have good residuals?

```{r, echo=FALSE, fig.height=5, fig.width=10}
res <- residuals(fit)

plot(res)
```

## Q-Q plot and histogram of the residuals:
```{r, echo=FALSE, fig.height=5.5, fig.width=10}
par(mfrow = c(1, 2))

qqnorm(res)

qqline(res, col = "red")

hist(res)
```

Hypothesis   | Test         | Result         | P-value
------------ | ------------ | -------------- | ------------------------------
Normality    | Shapiro-Wilk |     rejected   | `r shapiro.test(res)$p.value`
Unbiasedness | Wilcoxon     | not rejected   | `r wilcox.test(res)$p.value`
Stationarity | KPSS         | not rejected   | `r kpss.test(res)$p.value`

## Forecast the last year using the manual model
```{r}
fit_short <- Arima(train_set, model = fit)

fc <- forecast(fit_short, h = test_length)

accuracy(fc, test_set)
```

```{r, fig.height=5, fig.width=10}
plot(fc, ylab = title, xlab = "Time")

total_set <- c(train_set, test_set)

lines(total_set, col = "red")
```

# ETS model

## Create ETS model
```{r,}
fit_ets <- ets(time_series, biasadj = TRUE)

print(fit_ets)
```

## Plot of residuals
```{r, fig.height=5, fig.width=10}
tsdisplay(residuals(fit_ets))
```

```{rfig.height=5, fig.width=10}
par(mfrow = c(1, 2))
qqnorm(residuals(fit_ets))
qqline(residuals(fit_ets), col = "red")
hist(residuals(fit_ets))
```

Hypothesis   | Test         | Result         | P-value
------------ | ------------ | -------------- | ------------------------------
Normality    | Shapiro-Wilk | not rejected   | `r shapiro.test(residuals(fit_ets))$p.value`
Unbiasedness | Wilcoxon     | not rejected   | `r wilcox.test(residuals(fit_ets))$p.value`
Stationarity | KPSS         | not rejected   | `r kpss.test(residuals(fit_ets))$p.value`

## Forecast the last year using the ETS model
```{r}
fit_short <- ets(time_series, model = fit_ets)

fc <- forecast(fit_short, h = test_length)

accuracy(fc, test_set)
```

```{r, fig.height=5, fig.width=10}
plot(fc, ylab = title, xlab = "Time")

total_set <- c(train_set, test_set)

lines(total_set, col = "red")
```

# Final model selection

## Comparing the residuals of two ARIMAs:
```{r, fig.height=8, fig.width=8}
res      <- residuals(fit, type = "response")
res_auto <- residuals(fit_auto, type = "response")

plot(res, res_auto, xlim = c(min(res, res_auto), max(res, res_auto)),
     ylim = c(min(res, res_auto), max(res, res_auto)),
     xlab = "Residuals of manually found model",
     ylab = "Residuals of auto.arima model")

grid()

lines(c(min(res, res_auto), max(res, res_auto)) * 2,
      c(min(res, res_auto), max(res, res_auto)) * 2, col = "red")
```
```{r, echo=F}
dm.test(res, res_auto)
```

### Notes:
Diebold-Mariano test (p-value = 0.1096) does not find the differences between forecasting errors of two ARIMAs significant. 
The residuals of two models have the same properties. 
Automatic model has smaller AICc, so we'll use the automatic model.

## Comparing the residuals of the best ARIMA and the best ETS models:
```{r fig.width=8, fig.height=8}
res_ets <- residuals(fit_ets, type = "response")

plot(res_auto, res_ets,
     xlab = "Residuals, best ARIMA",
     ylab = "Residuals, best ETS",
     xlim = c(min(c(res_auto, res_ets), na.rm = TRUE),
              max(c(res_auto, res_ets), na.rm = TRUE)),
     ylim = c(min(c(res_auto, res_ets), na.rm = TRUE),
              max(c(res_auto, res_ets), na.rm = TRUE)))

lines(c(min(c(res_auto, res_ets),
            na.rm = TRUE), max(c(res_auto, res_ets), na.rm = TRUE)),
      c(min(c(res_auto, res_ets), na.rm = TRUE),
        max(c(res_auto, res_ets), na.rm = TRUE)), col = "red")
```

```{r, echo=F}
dm.test(res_auto, res_ets)
dm.test(res_auto, res_ets, alternative = "less")
```

### Notes:
Diebold-Mariano test says ARIMA is better. and AIC, AICc, BIC of ARIMA are smaller than those of ETS.
So we'll use ARIMA(4,0,5)(1,1,2)[12] as our final model.

## Forecast the last year using our final model
```{r}
fit_short <- Arima(train_set, model = fit_auto)

fc <- forecast(fit_short, h = test_length)

accuracy(fc, test_set)
```


```{r, fig.height=5, fig.width=10}
plot(fc, ylab = title, xlab = "Time")

total_set <- c(train_set, test_set)

lines(total_set, col = "red")
```